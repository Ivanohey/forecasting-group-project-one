## 4.5 Lichtenstein{.tabset}

```{r, warning=FALSE, echo=FALSE}
# Investigating Lichtenstein closely before 2008
Lichtenstein_before_2008 <- data_elec %>% 
  select(Date,Lichtenstein) %>% 
  filter(Date <= as.Date("2008-01-01"))
autoplot(Lichtenstein_before_2008)

# Investigating Lichtenstein closely after 2008
Lichtenstein_after_2008 <- data_elec %>% 
  select(Date,Lichtenstein) %>% 
  filter(Date >= as.Date("2008-01-01"))
autoplot(Lichtenstein_after_2008)
```
**Comment**

### Check the Stationarity by using Unit Root Test

```{r, warning=FALSE, echo=FALSE}
# Load the required package
library(tseries)

# Convert the data into a time series object
Lichtenstein_since_2010 <- data_elec %>% select(Date,Lichtenstein) %>% filter(Date >= as.Date("2010-01-01"))
ts_Lich <- ts(Lichtenstein_since_2010$Lichtenstein, frequency=12, start=c(2010,1))

# Check for linearity using ADF test
adf.test(ts_Lich)
```
```{r}
Lichtenstein_since_2010 %>% features(Lichtenstein_since_2010, unitroot_kpss)
```
In order to observe the stationarity assumption of Lichtenstein time serie. We have run the Unit Root Test which is a statistical test that checks for the presence of a unit root in a time series, which is an indication of non-stationarity.

Unit Root Test has the following hypothesis: 

$$H_0:$$ Data is stationary

$$H_a:$$ Data is non-stationary

In this case the Unit Root Test was performed on a the data Lichtenstein, and the test statistic was 3.20. The p-value of the test was 0.01 which indicates strong evidence to reject the null hypothesis of stationarity. Thus Lichtenstein time serie is non-stationary.

Based on it, we can use methods that assume non-stationarity, such as Random Walk Model, Autoregressive Integrated Moving Average (ARIMA), Exponential smoothing methods, Moving average models, Vector autoregression(VAR), ARIMA,SARIMA.


### **Testing Models**
Based on the previous analysis Lichtenstein data is stationary time series with high presence of trend and seasonality, thus we can consider using a simple ARIMA, Piece-Wise and . S-naive.

```{r, warning=FALSE, echo=FALSE}
#Split the data
training_Licht <- data_elec %>% select(Date, Lichtenstein) %>%  filter(Date < as.Date("2016-01-01"))
test_Licht <- data_elec %>% select(Date, Lichtenstein) %>% filter(Date >= as.Date("2016-01-01"))


# Fit ARIMA model and generate forecasts
data_fit_Licht_a <- training_Licht %>%
  model(ARIMA(Lichtenstein))
forecasts_Licht_a <- data_fit_Licht_a %>%
  forecast(h = 60)


# Fit ETS model and generate forecasts
data_fit_Licht_e <- training_Licht %>%
  model(ETS(Lichtenstein))
forecasts_Licht_e <- data_fit_Licht_e %>%
  forecast(h = 60)
forecasts_Licht_e$.mean <- ifelse(forecasts_Licht_e$.mean < 0, 0, forecasts_Licht_e$.mean)

# Fit seasonal naive model and generate forecasts
data_fit_Licht_n <- training_Licht %>%
  model(SNAIVE(Lichtenstein))
forecasts_Licht_n <- data_fit_Licht_n %>%
  forecast(h = 60)
forecasts_Licht_n$.mean <- ifelse(forecasts_Licht_n$.mean < 0, 0, forecasts_Licht_n$.mean)


# Fit piece wise model and generate forecasts
data_fit_Licht_pw <- training_Licht %>%
  model(piecewise = ARIMA(Lichtenstein ~ trend(knots = c(2008, 2009,2015,2016))))
forecasts_Licht_pw <- data_fit_Licht_pw%>%
  forecast(h = 60)
forecasts_Licht_pw$.mean <- ifelse(forecasts_Licht_pw$.mean < 0, 0, forecasts_Licht_pw$.mean)


# Combine forecasts into a single data frame
all_forecasts_Licht <- bind_rows(
  data.frame(Date = forecasts_Licht_a$Date, Method = "ARIMA", Forecast = forecasts_Licht_a$.mean),
  data.frame(Date = forecasts_Licht_e$Date, Method = "ETS", Forecast = forecasts_Licht_e$.mean),
  data.frame(Date = forecasts_Licht_n$Date, Method = "SNAIVE", Forecast = forecasts_Licht_n$.mean),
  data.frame(Date = forecasts_Licht_pw$Date, Method = "PIECE WISE", Forecast = forecasts_Licht_pw$.mean))

# Plot all three sets of forecasts together
data_elec %>% autoplot(Lichtenstein) +
  geom_line(data = all_forecasts_Licht, aes(x = Date, y = Forecast, color = Method)) +
  labs(title = "Electricity Demand in Lichtenstein")

```

###**Measuring Model Accuracy**

```{r}
#Accuracy
Licht_accuracy_a <-data_fit_Licht_a %>%
  refit(test_Licht) %>%
  accuracy()

Licht_accuracy_e <-data_fit_Licht_e %>%
  refit(test_Licht) %>%
  accuracy()

Licht_accuracy_n <-data_fit_Licht_n %>%
  refit(test_Licht) %>%
  accuracy()

Licht_accuracy_pw <- data_fit_Licht_pw %>%
  refit(test_Licht) %>%
  accuracy()

Licht_accuracy_table <- rbind(
  data.frame(Licht_accuracy_a),
  data.frame(Licht_accuracy_e),
  data.frame(Licht_accuracy_n),
  data.frame(Licht_accuracy_pw))


Licht_accuracy_table

#AIC
report(data_fit_Licht_a)
report(data_fit_Licht_e)
report(data_fit_Licht_n)
report(data_fit_Licht_pw)

```
A low AIC value is desirable as it indicates a better trade-off between model fit and complexity. Thus

### **Residuals**
Interesting to examine any outliers or extreme values in the residuals.
```{r}
gg_tsresiduals(data_fit_Licht_a) + labs(title = "ARIMA Lichtenstein residuals analysis")

gg_tsresiduals(data_fit_Licht_e) + labs(title = "ETS Lichtenstein residuals analysis")

gg_tsresiduals(data_fit_Licht_n) + labs(title = "SNAIVE Lichtenstein residuals analysis")

gg_tsresiduals(data_fit_Licht_pw) + labs(title = "PIECE WISE Lichtenstein residuals analysis")
```

## Result
Although all of these metrics are valuable for evaluating forecast accuracy, we have chosen to place greater emphasis on the AIC. This decision is based on the fact that the AIC takes into account both the model's fit to the data and its complexity. Consequently, we have selected the ETS model as the preferred choice for forecasting electricity demand in Lichtenstein


Since we can't have negative values, I decided to just set the negative ones to 0. 

This forecast actually doesn't look great. I would expect the next upward bounce to be of similar amplitude as the previous ones, but it seems like the forecast of the next bounce is only half the amplitude of the previous ones. 
